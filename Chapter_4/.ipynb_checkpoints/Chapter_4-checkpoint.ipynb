{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4730a706-4cd6-454d-89a8-1b1b995058c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f8964-746f-4d64-96c9-386c65b1bf86",
   "metadata": {},
   "source": [
    "# Chapter 4: Implementing a GPT model from scratch to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404fd46-595a-453e-8a44-067991509ea5",
   "metadata": {},
   "source": [
    "## 4.1 Coding an LLM Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ebba246-92ae-48dc-819c-2524ac1eb5dc",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    \n",
    "We previously used smaller embedding dimensionality for simplicity, but now we are scaling up to the size of the small GPT-2 model, specifically, the smallest version with 124 million parameters.\n",
    "\n",
    "In the context of deep learning, parameters refers to the trainable weights of the model that are adjusted and optimized during the training rocess to mininmize a specific loss function, this optimization allows the model to learn from the training data. For example, in a NN that is represented by a 2048x2048-dimensional matrix of weight, each element in the matrix is a paramter. This means this specific model would have 2048<sup>2</sup> parameters (4,194,304).\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "This is the architecture of a GPT model and what we will have built by the end of this chapter\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.1_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "This figure illustrates the order in which we tackle the individual concepts required to code the final GPT architecture\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.1_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6780cc5e-4320-4271-bc5b-16c639f8f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48eb6584-4d6b-4a78-b876-8c013fb4e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf1682b-1baf-4be4-89ab-4cb9b7c87489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46532f16-458b-408b-a6a1-5ca0f3b9dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3edb2-996a-431a-af40-775073fc1a7d",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Big picture overview showcasing how data is tokenized, embedded, and fed into the GPT model. The output embeddings represent the context vectors\n",
    "\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/4.1_3.png)\n",
    "\n",
    "</div>\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "687a56e6-11bf-4207-ad4d-c9c3ab495fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([6109, 3626, 6100,  345]), tensor([6109, 1110, 6622,  257])] \n",
      "\n",
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "print(batch,\"\\n\")\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30775c9c-f40f-4306-bb67-b92d28597864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1f935-47c4-4169-809d-20c3b78ffd95",
   "metadata": {},
   "source": [
    "## 4.2 Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537983e0-c5bd-4639-8d0d-668a85e0ec9c",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Problems like vanishing gradient or exploding gradient can lead to unstable training dynamics and make it difficult for the network to adjust its weights, resulting in difficulty to find a set of parameters (weights) that minimizes the loss function during training.\n",
    "\n",
    "The main idea of layer normalization is to adjust the activations (outputs) of a neural network layer to have a mean of 0 and a variance of 1, also known as unit variance. This adjustment will speed up the time it takes to converge, and will ensure reliable training.\n",
    "\n",
    "In modern LLM architectures, layer normalization is applied before and after the multi-head attention module, and, before the final output layer.\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.2_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1e74a7-faaf-4a2b-85fc-6f9b27c34ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
      "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]]) \n",
      "\n",
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "print(batch_example, \"\\n\")\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec26d13-1d18-4523-975f-0dbb97309463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3229a00a-c1bd-46f8-83fa-2ca3b74cee50",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "If we have a two-dimensional tensor (matrix) with dimensions [rows, columns], using dim=0 will perform the operation across rows (vertically, as shown at the bottom), resulting in an outpout that aggregates on the data for each column. Using dim=1 (or -1) will perform the operation across columns (horizontally, as shown at the top), resulting in an output aggregating the data for each row\n",
    "\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/4.2_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327f967a-abf2-445c-afdf-1be69d37baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[4, 6]]) \n",
      "\n",
      "tensor([[3],\n",
      "        [7]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.arange(1, 5).reshape(2, 2)\n",
    "print(test, \"\\n\")\n",
    "print(test.sum(dim=0, keepdim=True), '\\n')\n",
    "print(test.sum(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fba25d3-a970-47d8-99c7-9fd80f016bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Var:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Var:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1916709-d9db-4eee-b324-fd956867d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcff214e-7344-4122-b03d-8b74652f78d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Var:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True, unbiased=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Var:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4b4ab-8c4d-44d9-945a-882db4b15a28",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We have now implemented two of the building blocks necessary to complete the GPT architecture, next we will look at the GELU activation function, which is one of the activation functions used in LLMs, instead of the traditional ReLU function we used previously.\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/4.2_3.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2926854-1231-4938-8086-8b267d09cdb1",
   "metadata": {},
   "source": [
    "## 4.3 Implementing a feed forward network with GELU activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59e5d1-691d-4507-b8e0-d730d2cb80de",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Next, we implement a small neural network submodule used as part of the transformer block in LLMs. We begin by implementing GELU activation function, which plays a crucial role in this neural network submodule.\n",
    "\n",
    "Several other activation functions such as GELU (<i>Gaussian error linear unit<i>) and SwiGLU (<i>Swish-gated linear unit</i>) are used over ReLU because they offer improved performance for deep learning models, unlike the simpler ReLU.\n",
    "\n",
    "GELU = input_x * cumulative distribution function of the standard Gaussian distribution of x\n",
    "\n",
    "However, in practice is common to implement a computationally cheaper approximation that was found via curve fitting.\n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.3_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38df94da-92f2-49ce-9579-7aa2f1859c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf86bcba-6b9b-4977-b60b-983c5d2c1ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"RELU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e75b28-84e2-4458-aa22-f0fd00bbf640",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The smoothness of GELU can lead to better optimization properties during training, as it allows for more nuanced adjustments during training. In contrast, ReLU's sharp corner at zero can sometimes make optimizations harder, especially in very deep and complex architectures. \n",
    "\n",
    "Moreover, GELU allows for small, non-zero output for negative values. This means that during the training process, neurons that receive negative input can still contribute to the learning process, albeit to a lesser extent than positive inputs\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e005fd-7c86-45e3-8846-e6e5159e8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d5ca7-763c-403d-9f85-70a1c996ffd7",
   "metadata": {},
   "source": [
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.3_2.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836e19d3-35f8-45e4-9b7c-95be34578bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148af54a-19cc-482b-9d24-efeffd3be55a",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The FeedForward module plays a crucial role in enhancing the model's ability to learn from and generalize the data. It internally expands the embedding dimension into a higher dimensional space through the first linear layer, then performs the GELU activation and then a contraction back to the original dimension with the second linear transformation.\n",
    "\n",
    "Moreover, the uniformity in input and output dimensions simplifies the architecture by enabling the stacking of multiple layers without the need to adjust dimensions between them, thus making the model more scalable\n",
    "\n",
    "</h4>\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/4.3_3.png)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c4c8c-3a0e-48e4-b399-bc00b9935cf8",
   "metadata": {},
   "source": [
    "## 4.4 Adding shortcut connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506dd53-7976-4937-ab72-089f294f10e3",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Shortcut connections create an alternative, shorter path for the gradient to flow through the network by skipping one or mmore layers, which is achieved by adding the output of one layer to the output of a lateral layer. They play a crucial role in perserving the flow of gradients during the backward pass during training. This mitigates the challenge of vanishing gradients.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/4.4_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3c31ae-2a9d-4553-ba33-52709f2b3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), \n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), \n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), \n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), \n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), \n",
    "                          GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "541f4f95-ef79-4327-9774-5ab812bcd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fcb8ad8-5d8c-4ebd-9fe9-10174592bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871cbbd-64d5-4c05-9bb5-6586544e91e0",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This code picks a loss function to compute how close the model output and the user-specified target (0 here) are. Then calling loss.backward() instructs PyTorch to compute the loss gradient for each layer in the model. Suppose there is a 3x3 weight matrix for a given layer, in that case a layer will have 9 gradient values of which we are printing the mean absolute gradient for every layer.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b56a4850-41e7-4cef-b5c5-44aef42e86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input) # notice how the gradient diminishes as you get from the last layer (4) to the first layer (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730313cb-0a05-4286-b09f-4b17f6b4f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4fc28-1b67-4547-b1fb-25153fce3c0b",
   "metadata": {},
   "source": [
    "## 4.5 Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f979b3-1767-439c-bbfc-826ce6498c40",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Now we will implement the transformer block, a fundamental building block of GPT and other LLM architectures. It combines multi-head attention, layer normalization, dropout, feedforward layers, and GELU activations. Later, it will be connected to the remaining parts of the GPT architecture.\n",
    "\n",
    "When a transformer block processes an input sequence, each token is represented by a fixed-size vector (768 in this case). The computations in this transformer block are designed to transform the vector in a way that preserves their dimensionality. \n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/4.5_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa24f286-2362-4328-bac3-84005b0c5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads == 0), \\\n",
    "        \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduces the projection dim to match the desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape \n",
    "        keys = self.W_key(x)            # shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)        # ^\n",
    "        values = self.W_value(x)         # ^\n",
    "        \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        \n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3651dfd-b0ef-41f7-9bc0-0c01eb627b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f84736d-3cc0-4758-840b-002346bd223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_key.weight.shape: torch.Size([768, 768])\n",
      "queries.shape: torch.Size([2, 12, 4, 64])\n",
      "attn_weights.shape x values.shape: torch.Size([2, 12, 4, 4]) x torch.Size([2, 12, 4, 64])\n",
      "context_vec.shape: torch.Size([2, 4, 12, 64])\n",
      "\n",
      "\n",
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"\\n\")\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2777511-1022-4221-ac00-435f3a1fa1a6",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This preservation of shape throughout the transformer block architecture is not incidental, but a crucial aspect of its design. It allows for effective application across a wide range of sequence-to-sequence tasks, where each output vector directly corresponds to an input vector, maintaining a one-to-one relationship.\n",
    "\n",
    "With the transformer block implemented, we now have all the building blocks necessary to implement the GPT architecture. \n",
    "\n",
    "<div style=\"max-width:500px\">\n",
    "    \n",
    "![](images/4.5_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f60796-9328-4fd9-b3ca-4530b0e4cfd6",
   "metadata": {},
   "source": [
    "## 4.6 Coding the GPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d93ba-8d71-460f-b445-0bec2494ef8e",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This is an overview of the GPT model architecture showing how data flows through the model. Starting at the beginning, tokenized text is converted into token embeddings, then modified to include positional embeddings. This forms a tensor that is sequentially passed through transformer blocks (12 for this model) of which the number depends on the models size and specific architecture. Each of these transformer blocks contains multi-head attention and feedforward neural network layers with dropout and layer normalization.\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/4.6_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "459be6b3-5296-41a9-a118-65f4e1202dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790330e-7712-4afc-a1d0-5d07375313a8",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    \n",
    "In the constructor:\n",
    "    \n",
    "1. Initializes the token and positional embedding matrix \n",
    "2. Creates a sequential stack of transformer blocks equal to the number of layers specified in the cfg\n",
    "3. Initializes a final LayerNorm for the output the transformer block stack\n",
    "4. Initializes a linear output head that projects the output into the vocabulary space of the tokenizer to generate logits for each token in the vocab\n",
    "\n",
    "In the forward:\n",
    "1. Takes a batch of input token indices and computes their word and positional embeddings\n",
    "2. Combines them into one tensor, then passes it through the series of transformer blocks\n",
    "3. Applies the final LayerNorm to the output\n",
    "4. Then computes the logits, representing the next token's unormalized probabilities\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8408be7e-2814-48f0-8f93-a5d2ee46d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d84fcdd-1ada-42ea-b925-e44ee5c4920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04e7d0-290c-4b6e-a845-384d5de97b8f",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Why does this model have more parameters than the 124-million parameter GPT model we were trying create ?\n",
    "\n",
    "The reason is weight tying. Meaning, the original GPT-2 architecture reuses the weights from the token embedding layer in its output layer. \n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b52869d-f0d8-407a-a880-67d4770dc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "536c9399-64fc-4d3f-a1c5-15f5d84328b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "# lets remove the output layer parameter count from the total GPT-2 model count\n",
    "total_params_gpt2 = (total_params - sum(p.numel() for p in model.out_head.parameters()))\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c91e2-0fee-46ec-b5c6-3461ee2cf591",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Weight tying reduces overall computation complexity of the model. However, in the authors experience, he has observed that using two seperate token embedding and output layers result in a better model. Therefore, we will keep the matrices seperate, instead of using the same matrix for both operations\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b67097-330b-47b3-ae8b-9fcadcd0e785",
   "metadata": {},
   "source": [
    "####################### Exercise 4.1 ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "674699c6-2327-40b7-8b0e-60fb2f3ed946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56,669,184\n"
     ]
    }
   ],
   "source": [
    "ffn_params = (sum(p.numel() for p in model.trf_blocks[0].ff.parameters())) * 12\n",
    "print(f\"{ffn_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a1af5bb-9c4f-479f-8725-6e5555375510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,320,768\n"
     ]
    }
   ],
   "source": [
    "mha_params = (sum(p.numel() for p in model.trf_blocks[0].att.parameters())) * 12\n",
    "print(f\"{mha_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc3c3e-feec-4814-b5a0-8ee0382bfd33",
   "metadata": {},
   "source": [
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9ee7cd7-8e69-4a35-b792-c97c9306da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# memory requirements of the 163 million parameter model\n",
    "\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50c882-ca85-44ea-8583-0d59acfca0ab",
   "metadata": {},
   "source": [
    "####################### Exercise 4.2 ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8dfab3da-044c-45a9-9120-98b92802eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 1024,\n",
    "    \"n_heads\": 16,\n",
    "    \"n_layers\": 24,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b33a9ef-52f8-4c18-9fca-e90ae962d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_L = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 1280,\n",
    "    \"n_heads\": 20,\n",
    "    \"n_layers\": 36,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ac452591-eb8c-4c4c-9d41-a1ea3def09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_XL = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 1600,\n",
    "    \"n_heads\": 25,\n",
    "    \"n_layers\": 48,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "52aba8e4-8eeb-4fa3-924f-1debfd0864d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_medium_model = GPTModel(GPT_CONFIG_M)\n",
    "gpt_large_model = GPTModel(GPT_CONFIG_L)\n",
    "gpt_xlarge_model = GPTModel(GPT_CONFIG_XL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1482ae22-7c3e-42e4-aac4-0ead8d351eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2-medium has parameter count: 406,212,608\n",
      "\n",
      "GPT2-large has parameter count: 838,220,800\n",
      "\n",
      "GPT2-xl has parameter count: 1,637,792,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def param_count(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    return total\n",
    "          \n",
    "print(f\"GPT2-medium has parameter count: {param_count(gpt_medium_model):,}\\n\")\n",
    "print(f\"GPT2-large has parameter count: {param_count(gpt_large_model):,}\\n\")\n",
    "print(f\"GPT2-xl has parameter count: {param_count(gpt_xlarge_model):,}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82ba77-9724-4302-afbb-caaa4a687174",
   "metadata": {},
   "source": [
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd49ff5-f651-4e99-a88b-aeab67351a9c",
   "metadata": {},
   "source": [
    "## 4.7 Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b50dc-0cd5-4189-bf77-445854c4b722",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "In this section, we implement the code that turns these output tensors into text.\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/4.7_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "This image showcases how text is generated by a generative model like GPT. With each iteration, the input context grows by appending the previously predicted word to the input context.\n",
    "There are a multitude of steps involved in the process that GPT goes through when taking an output tensor and generating text.\n",
    "\n",
    "1. Decoding the output tensors\n",
    "2. Selecting tokens based on the probability distribution\n",
    "3. Converting these tokens into human-readable text\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/4.7_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "This image showcases a single step in the text generation process. \n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "02fc7223-17c4-4879-b21d-0cea9b531383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93417a0-32cf-4c18-b8e3-afdeb6a63170",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This code is a simple implementation of a generative loop for a language model using PyTorch. It will iterate for a specified number of new tokens to be generated, crops the given context to the correct context_length for the model, computes predictions, then selected the next token based on the highest probability prediction (<b>greedy encoding</b>)\n",
    "\n",
    "In the next chapter, we will introduce sampling methods so that the model does not always select the most likely token. This will allow variability and creativity in the generated text. Also will prevent the same context generating the same output every time.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "db389cb3-bfe9-4720-8bad-151612e11ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716] \n",
      "\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "tensor([[15496,    11,   314,   716]])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded,\"\\n\")\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "print(encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "75f2f7fa-f3e0-45f7-ac55-e78466579589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "# Put the model into eval mode to prevent random components ex. dropout, which are only used during traning\n",
    "\n",
    "model.eval()\n",
    "out = generate_text_simple(model=model, idx=encoded_tensor, max_new_tokens=6, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a16f3323-784e-45e2-9d70-3ab773b06951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5ecd5-797e-4157-9340-71fd9f7425b2",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Model outputs gibberish because it has not yet been trained.\n",
    "    \n",
    "</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
