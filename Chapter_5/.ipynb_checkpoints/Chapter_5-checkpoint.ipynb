{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92225a7a-26ef-4cfa-b702-2cb60b5b84f6",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da321b-8b51-455f-9596-8d99ec3e3df4",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "In this chapter we implement a training function and pretrain the LLM. We learn about model evaluation techniques, a requirement for optimizing the LLM during the training process, and we how to load pretrained weights into our LLM\n",
    "\n",
    "\n",
    "<div style=\"max-width:750px\">\n",
    "    \n",
    "![](images/5.0_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a5aff-e9bc-4fdd-94df-fef7f7ec9ac2",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c9e99-72ca-45ff-b61d-8e4968c66307",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This figure shows the topics covered in this chapter, and what this section will cover\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/5.1_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e786-b388-47ed-9810-5d75cb28dc8f",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa8cfcbe-3257-4a20-97e3-9b6b332b8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2033a0ce-8001-460e-b4a7-08287bd9c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import previous_chapters\n",
    "from previous_chapters import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea76e41b-7954-45f2-b213-716330c83978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533c4fc-e1d5-4433-bd01-b3c7d796073c",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We will introduce two functions:\n",
    "\n",
    "1. text_to_token_ids\n",
    "2. token_ids_to_text\n",
    "\n",
    "These functions will handle the conversions between text and token_ids throughout the chapter\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/5.1_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6bfb932-f2bf-4b5a-8527-3d732570ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9fcc6f1-a82f-4eea-9bdc-d1f7297d4e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fdbdc3-f317-4461-a1da-8f686e02489c",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Model is still only producing gibberish because it has not yet been trained. To define what makes text coherent, we must implement a numerical method to evaluate the generated content, allowing us to monitor and enhance the model's performance during training.\n",
    "\n",
    "We will calculate a <i>loss metric</i> for generated outputs. This metric is an indicator of model training progress and success.\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6d40e-446b-4f3f-93b8-4651751f5156",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed5373-0e46-4b4f-9440-7b4a4d129d81",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The overall flow from input text to LLM-generated text is illustrated in this five step procedure.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/5.1_3.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "We need to perform these initial steps before we can compute a loss that measures the generated text quality.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a57a701c-fabf-4b3d-9384-319d444309e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]\n",
    "\n",
    "# targets are the inputs but shifted one position forward\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c89bbd9-5e9d-45e6-8000-ec88d69aa6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "baf646d6-b601-4ca8-839a-b52282897655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f64e8c-845b-4a0c-b8f9-98af50d30997",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We now want to evaluate the performance of the model's generated text numerically via a loss function.\n",
    "\n",
    "Using the loss function, we measure how far the target values are from the generated tokens (predicted values) and adjust the weight parameters to generate text that is more similar (matches) the target text.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"max-width:650px\">\n",
    "    \n",
    "![](images/5.1_4.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8580535a-d6a2-4cd1-8b27-d862507d3b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815399c-66a4-49ca-9b94-fb4501eecd16",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The goal of training is to increase the probability of the correct token relative to the other tokens, this way we ensure that the LLM consistently picks the correct next token as the one it generates.\n",
    "\n",
    "This image describes the main steps in calculating the loss for the probability scores of input batches\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/5.1_5.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ffdb15ff-7399-415d-a5e9-ac498d3ae76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b20f355e-0abc-4238-b6c1-e62be6615416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab475a-8597-406e-9f0b-24ec835350c4",
   "metadata": {},
   "source": [
    "<h4>\n",
    "We want to get the average log probability as close to 0, but in deep learning we dont want to push the log probability up to 0, rather, bring the negative average log probability down to 0. Thats why we calculate the negative average at the end.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c41f2c3f-1d8a-4879-9ec6-1f2b59e15e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59390145-16f9-4629-b52a-162f157f7c9f",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "This is known as <b>Cross Entropy Loss</b>\n",
    "\n",
    "This is a popular measure in machine learning that measures the difference between two probability distributions - the true label and the predicted label.\n",
    "\n",
    "In context of frameworks like PyTorch, the cross_entropy function computes this measure for discrete outcomes.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb3b804f-520b-4bed-a05a-3a277ac6f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bacd6b59-96dd-416c-90a0-eb7765296c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba08b54-a380-4986-b512-e578069f051a",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Previously, we applied the softmax function to the logits and selected the probability scores corresponding to our target IDs, and computed the negative average log probability, but the cross_entropy function takes care of all that.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8f4415f6-62bb-4ee7-96e7-ce4db20678b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af30007-a37a-4ae3-a0c4-57a41aba9670",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee17c10-0e99-4b28-88f3-16413907e223",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We will first prepare the training and validation datasets that will be used to train our LLM. Then we can calculat the cross entropy loss for the training and validation sets to see how the model is learning.\n",
    "\n",
    "<div style=\"max-width:650px\">\n",
    "    \n",
    "![](images/5.1_6.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "To compute the loss on training/validation datasets, we will use a very small text dataset, \"The Veridct\", a short story we previously tokenized in chapter 2.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1aef0d70-e688-4875-ab91-2e9f086a6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee1b4c5e-dfaf-48f6-9e30-9ce043f4d11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceef21-1869-427f-9a51-251ef3012ec9",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The dataset is small, but it is just for educational purpose. We want to be able to pretrain our model in a couple of minutes not a couple of weeks.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/5.1_7.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "The figure illustrates the process.\n",
    "\n",
    "1. Split input text into training and validation portions\n",
    "2. Tokenize the text\n",
    "3. Divide the tokenized text into chunks of user-specified length\n",
    "4. Shuffle the rows and organize the chunked text into batches for model training\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f8863d4-03de-42d2-9e71-3f9b7f1cf361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18431\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "print(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e78b044-39fd-46fa-9765-5d44caa5378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "'''\n",
    "Question:\n",
    "In this dataloader, we shuffle batches of input meaning that text we are using to pretrain the LLM is not being fed to the model in order, yes the sequences of len=context_length are in order, but the batches of these sequences are not. Why would we do this? How does this help training, arent we runing the temporal ordering of words by doing this?\n",
    "'''\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6cf6dc49-dcea-44f4-9fed-f08b0caf220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Val Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nVal Loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4ed4463-8eea-477f-b8fc-0e227d470263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c8862a8-6699-4300-b03e-292baee8f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Can use the previous utility function (computes loss for a single batch) in the proceeding function that computes the loss over all batches in a dataloader.\n",
    "'''\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dc725-4671-4242-b58c-b02b0de60932",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The calc_loss_loader will iterate through specified num_batches or all batches in the dataloader, accumulate the loss in the total_loss variable, and then compute the average loss over the total number of batches\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25a72a2a-dd46-422c-882b-6532d9329d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: tensor(10.9876, device='mps:0')\n",
      "\n",
      "Validation Loss: tensor(10.9811, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # mps for apple M_ chips\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training Loss:\", train_loss)\n",
    "print(\"\\nValidation Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e36cd-d135-4652-8b16-0c1a05ad3a3d",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Now that we have a way to measure the quality of generated text, we will train the LLM to reduce this loss so that it becomes better at generating text\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/5.1_8.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca4101-718f-4116-acd6-54f5d4dffbc2",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867b230-e184-4cfe-8a3f-a18f1e5de838",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We now implement the code for pretraining an LLM\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/5.2_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "The image illustrates the typical eight step process that we go through when training a neural network in PyTorch\n",
    "\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f81acb71-7104-4840-a7d5-ed8b805fbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], [] # initializes lists to track losses and tokens seen\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs): # starts the main training loop\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # resets loss gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # calculates loss gradients\n",
    "            optimizer.step() # updates model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0: # optional evaluation step\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context) # prints a sample text after each epoch\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02741ea-b5fa-45fb-afe4-dd5b838c1ec9",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Note that this function uses two functions that have not yet been defined:\n",
    "\n",
    "1. evaluate_model()\n",
    "2. generate_and_print_sample()\n",
    "\n",
    "The evaluate model function will print the training and validation set losses after each model update so we can evaluate whether the training improves the model. It will do this while the model is in eval mode to prevent gradient tracking and disable dropout when calculating the loss.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa18fc45-be3b-4643-9996-23a52c3e5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # dropout is disabled during evaluation for stable, reproducible results\n",
    "    with torch.no_grad(): # prevents gradient tracking (not needed during evaluation) to reduce computational overhead\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72602c4-8cd9-46af-8bf5-0d5fcd5d3404",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The generate_and_print_sample function is a convenience function we can use to track the models improvement in generating text as it continues to train. \n",
    "\n",
    "It takes a text snippet (start_context) as input, converts it to token IDs, and feeds it to the LLM to generate a text sample\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "27404e16-f0fe-4bec-b0c4-8675f14ab6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \")) # compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d5c3c46b-055a-4fb7-8d68-fa231a3fcb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.mps.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) # .parameters() method returns all trainable weight parameters of the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=5, eval_iter=5, start_context=\"Every effort moves you\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fd4634d9-bce9-4d28-9d1d-d073178890be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "train_losses = [l.cpu() for l in train_losses]\n",
    "val_losses = [l.cpu() for l in val_losses]\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a82ede-adb2-4c38-8d33-65295f56e322",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "As we can see, the training and validation loss start to decrease after the first epoch, but they start to diverge after the second epoch. The fact that the validation loss is much larger than the training loss is evidence of the model overfitting on the training data. We can confirm that the model is memorizing training data verbatim by searching for generated text snippets, such as \"quite insensible to the irony\" in \"The Verdict\" text file.\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/5.2_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "Next, we will cover different strategies for text generation for LLMs to reduce training data memorization and increase the originality of the LLM-generated text. \n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7120bb-6490-44ed-8d76-38bfc39794be",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e55be4-476c-4565-ba9b-f7abbebddfe6",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "In this section we will look at text generation strategies to generate more original text.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3610e38-d652-4904-a8db-70633ff3c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9de5b-998d-466e-b6e4-638fde67346f",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The generated token is selected at each generation step corresponding to the largest probability score among all tokens in the vocabulary. This means the LLM will always generate the same outputs even if we run the preceding generate_text_simple multitple times on the same start context\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c523a-42d9-446c-bbbb-f528ffa5f250",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843882f1-b228-4343-9c5b-d8e4ecf8eb1f",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Lets take a look at <b>temperature scaling</b>, a sampling method that adds a probabilistic selection process to the next-token generation task.\n",
    "\n",
    "Previously, we used torch.argmax() to select the next token to be generated by selecting the word with the highest probability, also known as <i>greedy encoding</i>. To generate text with more variety, we can replace argmax with a function that samples from a probability distribution.\n",
    "\n",
    "Lets illustrate the probabilistic sampling with the following example\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1b7300ca-cfc1-4642-8029-1f85b0ab2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "68597e55-e181-470d-80f9-3b94d63d526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the LLM is given the start context \"Every effort moves you\", and generates the following next-token logits\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bbec2894-8ad5-4596-87fe-7c865add595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# this is how it works in the generate_text_simple function\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9422-a7da-4d0e-b59f-341216ac542c",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "Since the largest probability is in index 3, the generated word is \"forward\".\n",
    "\n",
    "To implement a probabilistic sampling process, we can replace argmax with multinomial.\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "79fe6513-ae91-49eb-b009-db705d8e7e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634eeab7-430e-4c12-a358-b593288da152",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "The multinomial function will sample the next token proportional to its probability score, so \"forward\" is still the most likely word to be chosen, but it will not always choose it.\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6de51527-d9a3-4b15-a5f1-feb328d06250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample=[torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908bfc4-f587-4367-b4b4-fb6cf52b3e47",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    \n",
    "As you can see, the word \"forward\" is sampled a majority of the time but there are also times where other words such as \"closer\" and \"toward\" are sampled aswell. \n",
    "\n",
    "We can also use a concept called temperature scaling to further control the distribution and selection process. Temperature scaling is the act of dividing the logits by parameter T, where T is a number greater than 0.\n",
    "\n",
    "When T is close to 1, the distribution does not change much. \n",
    "\n",
    "When T is closer to 0, the larger the scores being passed into the softmax (recall that softmax pushes higher values to 1 and lower values to 0). Therefore, when larger values are passed to softmax the result is a distribution with increased probabilities of the most high probability words and decreased probabilities of the lower probability words.\n",
    "\n",
    "When T is larger than 1, the result is more uniformly distributed token probabilities\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c07882cc-c0bf-4c82-989e-227ea7068ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c04fee5-be69-4e50-93d2-6d0dec91b12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], \n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8ef64-7dcb-43b7-a936-134d01d0eb15",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b7c9c-a48d-4251-8a68-0f32a368e6ef",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "<i>Top-k sampling</i>, when combined with probabilistic sampling and temperature scaling, can improve text generation results. \n",
    "\n",
    "1. Choose in advance, a number of words k\n",
    "2. Keep the logit values of the k tokens with the largest values, and replace all others with -inf\n",
    "3. Apply softmax to get a legitimate probability distribution\n",
    "4. Randomly sample a word from within these remaining k most-probable words according to its probability\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/5.3_1.png)\n",
    "\n",
    "</div>\n",
    "    \n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5810279e-11bb-4e1a-b87d-c662b9f5e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top pos: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits) # logit values\n",
    "print(\"Top pos:\", top_pos) # token Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3cf4ed79-117d-41f4-8f0b-de49f3b73c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch where function to set the logit values of the tokens that are below the lowest logit value within the top-three selection to -inf\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], # identifies logits < the minimum in top-k\n",
    "    input=torch.tensor(float('-inf')), # assigns -inf to these lower logits\n",
    "    other=next_token_logits # retains original logits for all other tokens\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "447fd1c5-2bf2-4e19-b23e-2fafc05f1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75032cb8-36f1-4a5d-9e81-016f60ce2561",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d514f-990b-415f-bc0d-9594d89a3c5d",
   "metadata": {},
   "source": [
    "<h4>\n",
    "We can now apply temperature scaling and the multinomial function for probabilistic sampling to select the next token among these three non-zero probability scores to generate the next token\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9c9a2281-399c-42d2-8027-3703701da445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens): # forloop same as before: gets logits and only focuses on last time step.\n",
    "        idx_cond = idx[:, -context_size:] # only use the last n (n=context_size) tokens as input to the model\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # logits.shape = [batch, context_size, |V|]\n",
    "        logits = logits[:, -1, :] # get the 1 x |V| vector for the last word in the input (context_size[-1])\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id: # stops generating early if end-of-sequence token is encountered\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e13878bb-3d25-4a2a-820b-62ecb4f46121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you can remember work on that my hostess: \"interesting\": on that point\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=5,\n",
    "    temperature=2\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1b4e7-bff3-4435-bb63-c5c8ca23adea",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c0e81-c167-497c-8841-e357d7ebf746",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "We have demonstrated how computationally (and time) expensive pretraining an LLM is. Thus, it is important that we can save the LLM so we do not have to rerun the training every time we want to use it in a new session.\n",
    "\n",
    "Lets discuss how to save and load a pretrained model.\n",
    "\n",
    "<div style=\"max-width:600px\">\n",
    "    \n",
    "![](images/5.4_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52b565-0737-4c34-888d-ef71ddf3a947",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Saving a model is relatively straightforward in PyTorch. Generally, we save a models <i>state dict</i>, a dictionary mapping each layer to its parameters, using the torch.save function.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f82cc4fe-2231-4dd6-a413-51353976e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530ad09-a78b-42d1-ac20-a208c19b36c4",
   "metadata": {},
   "source": [
    "<h4>\n",
    "After saving a model, we can load the model weights into a new GPTModel instance\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3f541ad5-3136-4c82-ba49-6912bd52aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/q7z2__rx1m14p2t84cn3s7xr0000gn/T/ipykernel_44672/879948430.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41ed75-c240-48e2-bef0-1ce9917d491f",
   "metadata": {},
   "source": [
    "<h4>\n",
    "If we want to continue pretraining the model later, after saving, saving the optimizer state is also recommended. Adaptive optimizer (like AdamW) save additional parameters for each model weight. Without it, the optimizer resets, and the model may learn suboptimally or even fail to converge.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "831b95d5-6117-42aa-b124-b12269cc1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, \n",
    "    \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700c0a4-574b-4727-9842-29ebd47aadb7",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Then, we can restore and load both the model and optimizer states by first loading the saved data with torch.load, then using the load_state_dict method\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "148bfd3b-c472-463b-b574-796669eb579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/q7z2__rx1m14p2t84cn3s7xr0000gn/T/ipykernel_44672/2865937130.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c6cb1-23c8-445c-b1b5-44bc2cbfa10b",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2b185-9d80-4946-b69c-49a9523f1f48",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "OpenAI has openly shared the weights of their GPT-2 models, thus eliminationg the need to invest tens to hundreds of thousands of dollars in retraining the model on a large corpus ourselves. \n",
    "\n",
    "We can load these weights into our GPTModel class and use it for text generation. <i>Weights</i> is referring to the weight parameters stored in the .weight attribute of PyTorch's Linear and Embedding layers, for example.\n",
    "\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063b267-023a-4269-88b8-eca3eda30345",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Choose Model\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3b065315-1616-4d49-bbe3-71fa8ddd8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small-124M\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium-355M\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large-774M\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl-1558M\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-xl-1558M\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9202f-9dba-41a2-9b1a-8af6a6d31fdc",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Download File\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aa0dbc19-d6e6-4578-8f86-fa4bafcb3f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to gpt2-xl-1558M.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_name = f\"{CHOOSE_MODEL}.pth\"\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c4812-a817-4bd3-8730-43a4d0803b81",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Load Weights\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c19352fa-54f8-4f58-93ae-defba7203867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1600)\n",
       "  (pos_emb): Embedding(1024, 1600)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (36): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (37): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (38): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (39): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (40): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (41): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (42): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (43): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (44): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (45): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (46): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (47): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_key): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (W_value): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (out_proj): Linear(in_features=1600, out_features=1600, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1600, out_features=6400, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=6400, out_features=1600, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4bc4b51c-4f47-48ad-bb48-160ad382fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you away from these self-\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=5,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=45,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
