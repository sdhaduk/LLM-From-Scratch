{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ea6887-3d70-4f9c-9649-beb58010be29",
   "metadata": {},
   "source": [
    "# Chapter 7: Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a8afa-1cb9-437c-8cab-ac3b3d0e0534",
   "metadata": {},
   "source": [
    "## 7.1 Introduction to instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6467cfe-d93c-4f15-ad10-63eec80e76fb",
   "metadata": {},
   "source": [
    "#### We know that a pretrained LLM is capable of text completion, meaning it can finish sentences or write text paragraphs given a fragment as input. However, pretrained LLMs often struggle with specific instructions, such as, \"Fix the grammer in this text\" or \"Convert this text to passive voice\". \n",
    "\n",
    "#### We will focus on improving the LLMs ability to follow such instruction and generate a desired response. \n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.1_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### We we will begin with the first stage in the three stage instruction fine-tuning process.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.1_2.png)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f095952-2670-43e5-8e12-507d88115902",
   "metadata": {},
   "source": [
    "## 7.2 Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f34f1-fd36-4933-a609-99a9f0658506",
   "metadata": {},
   "source": [
    "#### We will download and format the instruction dataset for instruction fine-tuning a pre-trained LLM. This dataset contains 1,100 instruction-response pairs similar to those in the first figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14577929-69da-43a5-a840-a27d9edca1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b455796-1b9a-4d31-a918-87e2a993648e",
   "metadata": {},
   "source": [
    "#### This code implements and executes a function that downloads the dataset and puts it into JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fabfc2-d2d1-4079-8a7c-d767484b73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ae4b3-177d-4b5a-a67c-a641b34c050e",
   "metadata": {},
   "source": [
    "#### As we can see, each example is a dictionary containing 'instruction', 'input', and 'output'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8392ad97-ee8b-4a5f-b5b6-f31b79a1d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f551820-a5b8-4520-90eb-0c61ae57a6f0",
   "metadata": {},
   "source": [
    "#### As shown above, the 'input' field may occasionally be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9ec09-ff71-4f02-8341-7afd30d230e4",
   "metadata": {},
   "source": [
    "#### Instruction fine-tuning involves training a model by providing it explicit input-output pairs. There are various ways to format these entires for LLMs. The figure below showcases two different example formats, known as 'prompt styles', used in the training of LLMs such as Alpaca and Phi-3.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/7.2_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### We will use the Alpaca prompty style because it is one of the most popular ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0cbb-4716-4f10-8226-76d56db403a8",
   "metadata": {},
   "source": [
    "#### Lets define a 'format_input' function that we can use to convert the entires in the data list into the Alpaca-style input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3044ad3d-cd89-4a7e-b685-69d92d901e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n###Instruction:\\n{entry['instruction']}\"\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \" \"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a970281f-c9d8-4573-9111-f177e0170420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "###Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3a0a6-84e4-4643-9dae-ab77425c18d1",
   "metadata": {},
   "source": [
    "#### Before we set up dataloaders, lets partition the dataset into a training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5f142a-b2a1-490d-bbc0-047873b4d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95004ccc-9e56-4f72-b902-358a99dbab23",
   "metadata": {},
   "source": [
    "#### Now we can focus on developing the method for construction training batches for fine-tuning the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfef74c-44b4-4926-88fd-053ddcf567e5",
   "metadata": {},
   "source": [
    "## 7.3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d4a1c-1d00-4634-9a5d-2a6fb3dbaf19",
   "metadata": {},
   "source": [
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Previously, the training batches were created automatically by the PyTorch DataLoader class, which employs a 'collate' function to combine lists of samples into batches. A collate function takes a list of individual samples and merges them into a single batch.\n",
    "\n",
    "#### However, for instruction fine-tuning, we are required to create our own collate function that plug into the DataLoader. We implement this custom collate function to handle the specific requirements and formatting our instruction fine-tuning dataset.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### The figure above breaks down the batching process into several steps. \n",
    "\n",
    "#### First, to implement steps 2.1 and 2.2, we create an InstructionDataset class that applies format_input and pretokenizes all inputs in the dataset. This two step process is detailed below, and is implemented in the __init__ constructor method of the InstructionDataset class.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/7.3_3.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e236dd5f-3953-4f5d-b9eb-ffcbccfcc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n###Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959bd5f-c418-4fad-920f-b46caba12a21",
   "metadata": {},
   "source": [
    "#### Similar to the approach used for classification fine-tuning, we want to collection multiple training examples in a batch, which necessitates padding all inputs to the same length which we do by appending the token ID for the <|endoftext|> token to the pretokenized inputs directly.\\\n",
    "\n",
    "#### Moving onto step 2.3 of the process, we develop a custom collate function that we can pass to the data loader. This custom collate function pads the training example in each batch to the same length while allowing different batches to have different lengths. This way, we avoid unncessary padding by only extending sequences to the longest one in the batch, not the whole dataset.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_4.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2e0ea38-5992-4d3e-b4eb-e0fbea124a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) # finds longest sequences in the batch\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b251b6-e4a0-4406-9108-ef8076b92d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9f2e5-fe1d-4de6-906f-a87f6ef6241c",
   "metadata": {},
   "source": [
    "#### We have implemented our first custom collate function to create batches from lists of inputs. Now, we must modify it to also create the target token IDs corresponding to the batch of input IDs.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_5.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e061f2f-ce16-4fc3-90b5-2906aef0826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) # finds longest sequences in the batch\n",
    "    inputs_lst, target_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
