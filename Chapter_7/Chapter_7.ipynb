{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ea6887-3d70-4f9c-9649-beb58010be29",
   "metadata": {},
   "source": [
    "# Chapter 7: Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a8afa-1cb9-437c-8cab-ac3b3d0e0534",
   "metadata": {},
   "source": [
    "## 7.1 Introduction to instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6467cfe-d93c-4f15-ad10-63eec80e76fb",
   "metadata": {},
   "source": [
    "#### We know that a pretrained LLM is capable of text completion, meaning it can finish sentences or write text paragraphs given a fragment as input. However, pretrained LLMs often struggle with specific instructions, such as, \"Fix the grammer in this text\" or \"Convert this text to passive voice\". \n",
    "\n",
    "#### We will focus on improving the LLMs ability to follow such instruction and generate a desired response. \n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.1_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### We we will begin with the first stage in the three stage instruction fine-tuning process.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.1_2.png)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f095952-2670-43e5-8e12-507d88115902",
   "metadata": {},
   "source": [
    "## 7.2 Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f34f1-fd36-4933-a609-99a9f0658506",
   "metadata": {},
   "source": [
    "#### We will download and format the instruction dataset for instruction fine-tuning a pre-trained LLM. This dataset contains 1,100 instruction-response pairs similar to those in the first figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14577929-69da-43a5-a840-a27d9edca1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b455796-1b9a-4d31-a918-87e2a993648e",
   "metadata": {},
   "source": [
    "#### This code implements and executes a function that downloads the dataset and puts it into JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fabfc2-d2d1-4079-8a7c-d767484b73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ae4b3-177d-4b5a-a67c-a641b34c050e",
   "metadata": {},
   "source": [
    "#### As we can see, each example is a dictionary containing 'instruction', 'input', and 'output'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8392ad97-ee8b-4a5f-b5b6-f31b79a1d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f551820-a5b8-4520-90eb-0c61ae57a6f0",
   "metadata": {},
   "source": [
    "#### As shown above, the 'input' field may occasionally be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9ec09-ff71-4f02-8341-7afd30d230e4",
   "metadata": {},
   "source": [
    "#### Instruction fine-tuning involves training a model by providing it explicit input-output pairs. There are various ways to format these entires for LLMs. The figure below showcases two different example formats, known as 'prompt styles', used in the training of LLMs such as Alpaca and Phi-3.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/7.2_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### We will use the Alpaca prompty style because it is one of the most popular ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0cbb-4716-4f10-8226-76d56db403a8",
   "metadata": {},
   "source": [
    "#### Lets define a 'format_input' function that we can use to convert the entires in the data list into the Alpaca-style input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3044ad3d-cd89-4a7e-b685-69d92d901e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \" \"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a970281f-c9d8-4573-9111-f177e0170420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3a0a6-84e4-4643-9dae-ab77425c18d1",
   "metadata": {},
   "source": [
    "#### Before we set up dataloaders, lets partition the dataset into a training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5f142a-b2a1-490d-bbc0-047873b4d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95004ccc-9e56-4f72-b902-358a99dbab23",
   "metadata": {},
   "source": [
    "#### Now we can focus on developing the method for construction training batches for fine-tuning the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfef74c-44b4-4926-88fd-053ddcf567e5",
   "metadata": {},
   "source": [
    "## 7.3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d4a1c-1d00-4634-9a5d-2a6fb3dbaf19",
   "metadata": {},
   "source": [
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Previously, the training batches were created automatically by the PyTorch DataLoader class, which employs a 'collate' function to combine lists of samples into batches. A collate function takes a list of individual samples and merges them into a single batch.\n",
    "\n",
    "#### However, for instruction fine-tuning, we are required to create our own collate function that plug into the DataLoader. We implement this custom collate function to handle the specific requirements and formatting our instruction fine-tuning dataset.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_2.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### The figure above breaks down the batching process into several steps. \n",
    "\n",
    "#### First, to implement steps 2.1 and 2.2, we create an InstructionDataset class that applies format_input and pretokenizes all inputs in the dataset. This two step process is detailed below, and is implemented in the __init__ constructor method of the InstructionDataset class.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/7.3_3.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e236dd5f-3953-4f5d-b9eb-ffcbccfcc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n###Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959bd5f-c418-4fad-920f-b46caba12a21",
   "metadata": {},
   "source": [
    "#### Similar to the approach used for classification fine-tuning, we want to collection multiple training examples in a batch, which necessitates padding all inputs to the same length which we do by appending the token ID for the <|endoftext|> token to the pretokenized inputs directly.\n",
    "\n",
    "#### Moving onto step 2.3 of the process, we develop a custom collate function that we can pass to the data loader. This custom collate function pads the training example in each batch to the same length while allowing different batches to have different lengths. This way, we avoid unncessary padding by only extending sequences to the longest one in the batch, not the whole dataset.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_4.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e0ea38-5992-4d3e-b4eb-e0fbea124a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) # finds longest sequences in the batch\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b251b6-e4a0-4406-9108-ef8076b92d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c9f2e5-fe1d-4de6-906f-a87f6ef6241c",
   "metadata": {},
   "source": [
    "#### We have implemented our first custom collate function to create batches from lists of inputs. Now, we must modify it to also create the target token IDs corresponding to the batch of input IDs.\n",
    "\n",
    "<div style=\"max-width:700px\">\n",
    "    \n",
    "![](images/7.3_5.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e061f2f-ce16-4fc3-90b5-2906aef0826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch) # finds longest sequences in the batch\n",
    "    inputs_lst, target_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25988d67-16e9-464e-adb0-94f86780e41a",
   "metadata": {},
   "source": [
    "#### We want to assign a -100 placeholder value to all padding tokens. This allows us to exlude these padding tokens from contributing to the training loss calculation, ensuring that only meaningful data influences model learning. (We did not have to worry about this for classification fine-tuning because we only trained the model based on the last output token.)\n",
    "\n",
    "#### Note that we retain one end-of-text token, ID 50256, in the target list, this allows the LLM to learn when to generate an end-of-text token in reponse to instruction. This is used as an indicator that the generated response is complete.\n",
    "\n",
    "#### Now we modify our collate function to replace tokens with ID 50256 with -100 in target lists. We also introduce a allowed_max_length parameter to optionally limit the length of samples.\n",
    "\n",
    "<div style=\"max-width:800px\">\n",
    "    \n",
    "![](images/7.3_6.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5245c625-9e05-4d66-9d12-e36e9fa18d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item)) # pads sequence to max_length\n",
    "        inputs = torch.tensor(padded[:-1]) # truncates to last token for input\n",
    "        targets = torch.tensor(padded[1:]) # shifts +1 to the right for targets\n",
    "\n",
    "        mask = targets == pad_token_id # replaces all but the first padding tokens in targets by ignore_index\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35d21c1-4ad1-4ad8-8966-1697d24c0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81a204-84ce-4908-8ae9-e448ffcc4086",
   "metadata": {},
   "source": [
    "#### Lets explore the underlying purpose of this modification\n",
    "\n",
    "#### Consider this simple and self-contained example where each output logit corresponds to a potential token from the models vocabulary. Here's how we calculate cross entropy loss during training when the model predicts a sequence of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776abaf0-3b98-4540-99c0-9aeb034319c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f0d47-7050-40b7-a2f4-04a942fba147",
   "metadata": {},
   "source": [
    "#### Loss value calculated for previous code is 1.1269, and as we would expect, adding an additional token ID affects the loss calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8e2aeb-63b3-4c17-9f8c-1c437c204a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02953932-4cac-499a-8c2e-c37d81e43e15",
   "metadata": {},
   "source": [
    "#### Now lets see what happens when we replace the third target token ID with -100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "439240b6-a23f-40c6-9a7a-84f2769243ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c487e6-adc3-48d9-b4ae-b68138ae6cdf",
   "metadata": {},
   "source": [
    "#### The cross entropy loss function ignored the third entry in the targets_3 vector, the token ID corresponding to -100. The default setting of the cross entropy function in PyTorch ignores all targets labeled -100, and we can take advantage of this ignore additional padding tokens that we used to pad the trianing examples to have the same length in each batch.\n",
    "\n",
    "#### However, we want to keep one end-of-text token because it helps the LLM learn to generate end-of-text tokens, which we can use to indicate that a response is complete.\n",
    "\n",
    "#### In addition to masking out padding tokens, it is also common to mask out the target token IDs that correspond to the instruction. This results in the crosss entropy loss only being computed for the generated response target IDs, thus the model is trained to focus on generating accurate responses rather than memorizing instructions, which can help reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16879c1-df80-48a9-af1a-1c846dd6e9c1",
   "metadata": {},
   "source": [
    "## 7.4 Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fde5aa-e799-47ef-92f1-d146c178275a",
   "metadata": {},
   "source": [
    "#### We are ready to plug both InstructionDatset and the custom_collate_fn function into PyTorch data loaders.\n",
    "\n",
    "<div style=\"max-width:1000px\">\n",
    "    \n",
    "![](images/7.4_1.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff59ec1-6f9b-4bf8-b326-4ce7408658b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f45d87f3-99f3-40d1-ace8-65f7ad3bf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba256036-3ea5-42ba-851a-44f092cf126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import tiktoken\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 1\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d87e6954-cf20-441d-94bb-dfc6a8d5b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8c856-b021-4e56-b86c-38062fe21117",
   "metadata": {},
   "source": [
    "#### Thanks to our custom collate function, the data loader is able to create batches of with differing token sequence lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1a4fd-a3d2-4c06-8eb8-958fa86b0e81",
   "metadata": {},
   "source": [
    "## 7.5 Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e2156-ee2d-487f-87bc-c30aefcd9a9e",
   "metadata": {},
   "source": [
    "#### Now we load a pretrained GPT model that we want to fine-tune. Unlike before, when we loaded in the gpt-small model, this time we will load in the gpt-medium model because the small is too limited in capacity to achieve satisfactory results via instruction fine-tuning.\n",
    "\n",
    "<div style=\"max-width:1000px\">\n",
    "    \n",
    "![](images/7.5_1.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91307b88-f70c-455c-ab4c-1925356ef147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small-124M\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium-355M\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large-774M\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl-1558M\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium-355M\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "file_name = f\"{CHOOSE_MODEL}.pth\"\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "\n",
    "model = GPTModel(BASE_CONFIG).to(device)\n",
    "model.load_state_dict(torch.load(file_name, map_location=device, weights_only=True), strict=True)\n",
    "model.eval()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800235e-b431-4a5a-80a6-ee3dbb64a561",
   "metadata": {},
   "source": [
    "#### Lets assess the pretrained LLM's performance on one of the validation tasks by comparing its output to the expected response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3653f92-51a2-47f0-a8c9-11b371f2786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96939fd9-d970-4527-acf6-5d9da0bb2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import text_to_token_ids, token_ids_to_text, generate\n",
    "\n",
    "idx = text_to_token_ids(input_text, tokenizer).to(device)\n",
    "token_ids = generate(model=model, idx=idx, max_new_tokens=35, context_size=BASE_CONFIG[\"context_length\"], eos_id=50256)\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba46ad-eb4c-4c50-b894-a1f8dd79a796",
   "metadata": {},
   "source": [
    "#### The generate function concatenates the input and output text, but we only want to see the generated response so we can subtract the length of the input instruction from the start of generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52827b5c-e22b-4973-b748-f1f39c514208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' __________________________________________\n",
      "\n",
      "### Instruction\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c4cec-9866-4540-8211-58ef3f3d3772",
   "metadata": {},
   "source": [
    "## 7.6 Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab3e1a2-f050-4eb2-b3dc-9ff907e4a190",
   "metadata": {},
   "source": [
    "#### Now we take the loaded pretrained model and further train it using the previously prepared instruction dataset prepared earlier in the chaper. \n",
    "\n",
    "<div style=\"max-width:1000px\">\n",
    "    \n",
    "![](images/7.6_1.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6114e66-eaa2-41b0-8312-b21fabf8a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.788628101348877\n",
      "Validation loss: 3.97882661819458\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_loss_loader\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "torch.mps.empty_cache()\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5a3a6-82ce-426b-9cc9-6a1949cd2238",
   "metadata": {},
   "source": [
    "#### Initial loss values are above, remember, our goal is to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f04b7fcd-2739-4db0-9e3b-589b1c296fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.072, Val loss 3.095\n",
      "Ep 1 (Step 000100): Train loss 0.874, Val loss 1.017\n",
      "Ep 1 (Step 000200): Train loss 0.666, Val loss 0.978\n",
      "Ep 1 (Step 000300): Train loss 0.572, Val loss 0.878\n",
      "Ep 1 (Step 000400): Train loss 0.941, Val loss 0.846\n",
      "Ep 1 (Step 000500): Train loss 0.747, Val loss 0.842\n",
      "Ep 1 (Step 000600): Train loss 0.657, Val loss 0.816\n",
      "Ep 1 (Step 000700): Train loss 0.569, Val loss 0.721\n",
      "Ep 1 (Step 000800): Train loss 0.437, Val loss 0.739\n",
      "Ep 1 (Step 000900): Train loss 0.374, Val loss 0.623\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ###Response: The meal is prepared by the chef every day.<|endoftext|>The chef prepares the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:\n",
      "Ep 2 (Step 001000): Train loss 0.445, Val loss 0.674\n",
      "Ep 2 (Step 001100): Train loss 0.632, Val loss 0.718\n",
      "Ep 2 (Step 001200): Train loss 0.367, Val loss 0.700\n",
      "Ep 2 (Step 001300): Train loss 0.380, Val loss 0.638\n",
      "Ep 2 (Step 001400): Train loss 0.458, Val loss 0.659\n",
      "Ep 2 (Step 001500): Train loss 0.386, Val loss 0.671\n",
      "Ep 2 (Step 001600): Train loss 0.357, Val loss 0.625\n",
      "Ep 2 (Step 001700): Train loss 0.246, Val loss 0.527\n",
      "Ep 2 (Step 001800): Train loss 0.311, Val loss 0.590\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ###Response: The chef prepares the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The chef prepares the meal every day.  \n",
      "Training completed in 12.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import train_model_simple\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0000625, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=10, eval_iter=5, start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8811b0-9e4b-4c49-b5d2-70798e6e33ff",
   "metadata": {},
   "source": [
    "#### The training output shows the model is learning effectively, as we can tell by the consistently decreasing training and validation loss over the two epochs. \n",
    "\n",
    "#### We will revisit and evaluate the response quality of the model in more detail later. For now lets examine the training loss and validation curvees to gain additional insight into the model's learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d57470a-8657-49fc-a22b-88437f660454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c567a-eb06-469e-b766-6fc231d74ad6",
   "metadata": {},
   "source": [
    "#### From the loss plot shown above, we can see that the model's performance on both the training and validation sets improves substantially over the course of training. Then as training progresses to the second epoch, the losses continue to decrease but at a slower rate, suggesting that the model is fine-tuning its learned representations and converging to a stable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221f5aa-fe3a-4e82-bffe-a925bc8cdedb",
   "metadata": {},
   "source": [
    "## 7.7 Extracting and saving responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6029d2-f852-46d2-b808-d38a8897c1f0",
   "metadata": {},
   "source": [
    "#### Having fine-tuned the model on the training portion of the instruction dataset, we are now ready to evaluate its performance on the held-out test set. \n",
    "\n",
    "#### First, we extract the model-generated responses for each input in the test dataset and collect them for the manual analysis, and then we evaluate the LLM to quantify the quality of the responses.\n",
    "<div style=\"max-width:1000px\">\n",
    "    \n",
    "![](images/7.7_1.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a113413-4d2a-40e9-bbad-c644619a022c",
   "metadata": {},
   "source": [
    "#### To complete the response instruction step, we use the generate function. We then print the model responses alongside the expected test set answers for the first three test set entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f3210dc-1c73-4562-ad15-97181f2c4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "--------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms? \n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud is a cumulus (thin) cumulus (thin) cloud.\n",
      "--------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'. \n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(model=model, idx=text_to_token_ids(input_text, tokenizer).to(device), max_new_tokens=256, context_size=BASE_CONFIG[\"context_length\"], eos_id=50256)\n",
    "    \n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"###Response:\", \"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5532b3-2469-459b-8f09-71c3b1b435ef",
   "metadata": {},
   "source": [
    "#### As we can see based on the test set instructions, given response, and the model's responses, the model performs relatively well.\n",
    "\n",
    "#### More importantly, model evaluation is not as straightforward as it for classification fine-tuning, where we simply calculate the percentage of correct spam/non-spam class labels to obtain the classification accuracy. In practice, instruction fine-tuned LLMs such as chatbots are evaluated via multiple approaches:\n",
    "- #### Short answer and multiple choice benchmarks\n",
    "- #### Human preference comparison to other LLMs\n",
    "- #### Automated conversational benchmarks\n",
    "\n",
    "#### In practice it is useful to consider all three types of evaluation methods, however, since we are primarily interested in assessing conversational performance rather than just the ability to answer multiple choice questions, human evaluation and automated metrics may be more relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3ec8c-6ed3-4542-bf0b-051d4d85fd86",
   "metadata": {},
   "source": [
    "#### Human evaluations, while providing valuable insights, is relatively laborious and time consuming. Reading and assigning ratings to all 1,100 responses would require significant amount of effort. \n",
    "\n",
    "#### So, we implement an approach similar to conversational benchmarks, which involves evaluating the responses automatically using another LLM. This allows us to efficiently assess the quality of the generated responses without the need for extensive human involvement. \n",
    "\n",
    "#### We will use another LLM to evaluated our fine-tuned models responses, however instead of rely on a public benchmark dataset, we will use our own custom set. This allows for more targeted and relevant assessment of the model's performance within the context of our intended use case.\n",
    "\n",
    "#### To prepare responses for this evaluation process, we appened the generated responses to the test_set dictionary, and save the updated data as an \"instruction-data-with-response.json\" file for record keeping. The following code will iterate over the entire test set and append the responses to the test_set dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c220a4f2-2d09-47d6-837b-f0a5552a3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, entry in enumerate(test_data):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"###Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5946c4e-18bc-4c44-a20c-05f720db2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fb1b2-e4f8-4a63-bbb3-8c9caf30835a",
   "metadata": {},
   "source": [
    "#### Lets save the model before we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d142296b-5148-475c-8c0b-2c8d7d687bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium-355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e2b48-3b03-4559-846d-9ce65c0ee002",
   "metadata": {},
   "source": [
    "## 7.8 Evaluating the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36716aab-8625-49cc-b2ab-15652c1aad4a",
   "metadata": {},
   "source": [
    "#### We previously judged the performance of the model of an instruction-fine-tuned model by looking at its responses on three examples of the test set. Now we implemente a method to automate the response evaluation of the fine-tuned LLM using another, larger LLM.\n",
    "\n",
    "<div style=\"max-width:1000px\">\n",
    "    \n",
    "![](images/7.8_1.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### We will utilize an existing instruction fine-tuned model, Llama 3. Download an application called Ollama and make sure it is running. The following code will verify that the Ollama session is running properly before we use it to evaluate the test set responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bec410b-e1a2-4b7e-af95-1a3cd1ee9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama is not running. Launch it before proceeding.\")\n",
    "print(\"Ollama running:\", ollama_running)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ba089-4edf-419c-90ec-56210a75d6b1",
   "metadata": {},
   "source": [
    "#### The following code interacts with Ollama using its REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1ba4af6-2baf-4f6b-b791-af7b0cb954fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "def query_model(prompt, model=\"llama3.2\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    \n",
    "    request = req.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "    with req.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "517ac210-cc01-4207-8aac-b03bd0e2ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and grassy weeds.\n",
      "2. Hay: High-quality hay, such as timothy or alfalfa, is a staple in a llama's diet. It provides essential nutrients like fiber, protein, and energy.\n",
      "3. Grains: Llamas may also be fed grains like oats, corn, or barley, but these should not make up more than 10-15% of their diet.\n",
      "4. Fruits and vegetables: Fresh fruits and vegetables, such as apples, carrots, and sweet potatoes, can be given to llamas as treats or added to their hay.\n",
      "5. Browse: Llamas may also eat browse, which includes leaves, twigs, and other vegetation from trees and shrubs.\n",
      "\n",
      "It's essential to note that llamas have a unique digestive system, with a four-chambered stomach and a large cecum (a specialized part of the large intestine). This allows them to break down and extract nutrients from plant material more efficiently than many other animals. As a result, llamas require a diet rich in fiber and low in protein.\n",
      "\n",
      "A balanced llama diet should include:\n",
      "\n",
      "* 70-80% hay\n",
      "* 10-20% grains\n",
      "* 5-10% fruits and vegetables\n",
      "* 1-2% browse\n",
      "\n",
      "It's always best to consult with a veterinarian or experienced llama breeder to determine the specific dietary needs of your llama.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3.2\"\n",
    "result = query_model(\"What do llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c1c33-834b-4d75-8dfe-ab22b0a8e819",
   "metadata": {},
   "source": [
    "#### Using the query_model function defined earlier, we can evalaute the responses generated by our fine-tuned model that prompts the Llama 3 model to rate our fine-tuned model's responses on a scale from 1 to 100 based on the given test set response as reference\n",
    "\n",
    "#### Lets first apply it to three examples from the tests set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6470d821-d7b4-42d0-8097-49e97fae24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> To complete this task, I would rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "### Output:\n",
      "The car is as fast as lightning.\n",
      "\n",
      "Now, let's evaluate the model response \"The car is as fast as a bullet.\" on a scale from 0 to 100:\n",
      "\n",
      "Score: 80\n",
      "\n",
      "This response uses a simile, which meets the requirement. However, it's not the most common or idiomatic way to express speed in this context. The original response \"as fast as lightning\" is more commonly used and evokes a stronger sense of speed and power. The model response \"as fast as a bullet\" is also acceptable but might be considered less vivid or memorable than the original.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud is a cumulus (thin) cumulus (thin) cloud.\n",
      "\n",
      "Score:\n",
      ">> I would score the model response 0 out of 100.\n",
      "\n",
      "The correct output should be \"The type of cloud typically associated with thunderstorms is cumulonimbus.\" This response accurately identifies the type of cloud associated with thunderstorms and provides a clear and concise answer.\n",
      "\n",
      "The model response provided contains several errors:\n",
      "\n",
      "* The word \"is\" should not be followed by two separate instances of \"a\".\n",
      "* The description of the cloud as \"thin\" is incorrect, as cumulonimbus clouds are typically tall and dense.\n",
      "* The use of \"(thin) cumulus (thin) cloud\" is redundant and unclear.\n",
      "\n",
      "Overall, the model response does not provide an accurate or clear answer to the question, which is why it scores 0 out of 100.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> To answer this question correctly, I would need to be able to understand the context of the instruction and generate a response that meets the requirements.\n",
      "\n",
      "The correct output for the given input would be:\n",
      "\n",
      "\"The author of 'Pride and Prejudice' is Jane Austen.\"\n",
      "\n",
      "This response accurately completes the request by providing the name of the author of the book \"Pride and Prejudice\".\n",
      "\n",
      "As for scoring, I would give myself a score of 100% because the response directly answers the question without any additional information or context that might be required. The response is clear, concise, and accurate.\n",
      "\n",
      "However, if the instruction was to provide more context or details about Jane Austen, such as her biography or notable works, then my score would be lower, likely in the range of 80-90%.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and the correct output `{entry[\"output\"]}`, \"\n",
    "        f\"score the model response `{entry[\"model_response\"]}` \"\n",
    "        f\"on a scale from 0 to 100, where 100 is the best score.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39a5c8-9af3-4d79-81a1-3a87ebb6fbd1",
   "metadata": {},
   "source": [
    "#### The generated responses show how the LLama3 model is able to provide a score for the model outputs. We can modify the previous prompt to request LLama3 to only generate an integer score from 0 to 100. This change allows us to calculate an average score for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d24e1d9-1544-46a2-bd8f-30831b2891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model='llama3.2'):\n",
    "    scores = []\n",
    "    for entry in json_data:\n",
    "        prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and the correct output `{entry[\"output\"]}`, \"\n",
    "        f\"score the model response `{entry[json_key]}` \"\n",
    "        f\"on a scale from 0 to 100, where 100 is the best score. \"\n",
    "        f\"Only Respond with the integer score on a scale from 0 to 100, no other text.\"\n",
    "    )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2603648-391d-4765-b60f-53774b00dc54",
   "metadata": {},
   "source": [
    "#### We can now apply the generate_model_scores function to the entire test_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7adf98b3-9821-4b96-8b0a-540b0aff5372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 45.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604748e5-11ce-4d51-b8f1-69615031ab28",
   "metadata": {},
   "source": [
    "#### The evaluation output shows that our fine-tuned model achieves an average score of 46, which provides a useful benchmark for comparison against other models or for experimenting with different training configurations to improve the models performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
